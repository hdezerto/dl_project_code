{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f60fa1-7eb7-4e33-8b2d-d4d6025b0da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "*KTH Royal Institute of Technology* \\\n",
    "DD2424 Deep Learning in Data Science | Project (grade E part)\\\n",
    "Diogo Paulo 030224-8216 (diogop@kth.se)\\\n",
    "Hugo Dezerto 20011224-8257 (hugoad@kth.se) \\\n",
    "Maria Sebasti√£o 031010-T207 (mcms2@kth.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336f023-9bfb-4ea6-84da-1c2acb7afab4",
   "metadata": {},
   "source": [
    "# Grade E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b3315ba-0c7b-44c0-9418-d1d3bec4fab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/grade_E'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27642bdc-7bfc-4c86-a0d1-109542e774f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from torch.utils.data import random_split, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision # For make_grid and denormalizing\n",
    "\n",
    "# Set device. Use GPU if available else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20fd2f-8437-4766-909a-f73a96a14eb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ecada7d-a951-4319-84c9-87dddc6d1c0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Number of training samples: 3680 Number of test samples: 3669\n",
      "ResNet18 model loaded.\n",
      "Epoch 1, Loss: 0.1506\n",
      "Epoch 2, Loss: 0.0655\n",
      "Epoch 3, Loss: 0.0554\n",
      "Epoch 4, Loss: 0.0579\n",
      "Epoch 5, Loss: 0.0461\n",
      "Epoch 6, Loss: 0.0479\n",
      "Epoch 7, Loss: 0.0416\n",
      "Epoch 8, Loss: 0.0423\n",
      "Epoch 9, Loss: 0.0393\n",
      "Epoch 10, Loss: 0.0345\n",
      "Epoch 11, Loss: 0.0442\n",
      "Epoch 12, Loss: 0.0354\n",
      "Epoch 13, Loss: 0.0279\n",
      "Epoch 14, Loss: 0.0283\n",
      "Epoch 15, Loss: 0.0400\n",
      "Epoch 16, Loss: 0.0367\n",
      "Epoch 17, Loss: 0.0330\n",
      "Epoch 18, Loss: 0.0366\n",
      "Epoch 19, Loss: 0.0315\n",
      "Epoch 20, Loss: 0.0311\n",
      "Epoch 21, Loss: 0.0337\n",
      "Epoch 22, Loss: 0.0269\n",
      "Epoch 23, Loss: 0.0294\n",
      "Epoch 24, Loss: 0.0236\n",
      "Epoch 25, Loss: 0.0328\n",
      "Epoch 26, Loss: 0.0243\n",
      "Epoch 27, Loss: 0.0220\n",
      "Epoch 28, Loss: 0.0258\n",
      "Epoch 29, Loss: 0.0194\n",
      "Epoch 30, Loss: 0.0500\n",
      "Training time: 11.91 minutes\n",
      "Test Accuracy: 99.0188%\n"
     ]
    }
   ],
   "source": [
    "# --------------------- BINARY CLASSIFICATION ---------------------\n",
    "\n",
    "# Transform: Resize, normalize (ImageNet mean/std)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),        # Resize shortest side to 224, keep aspect ratio\n",
    "    transforms.CenterCrop(224),    # Crop from the center to 224x224\n",
    "    transforms.ToTensor(), # Convert to tensor\n",
    "    # Normalize with ImageNet mean and std (check https://pytorch.org/hub/pytorch_vision_resnet/)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset as binary classification problem (cat vs dog). The resulting object is a list of tuples (image, label)\n",
    "train_dataset = OxfordIIITPet(root='./dataset', split='trainval', target_types='binary-category', transform=transform, download=True)\n",
    "test_dataset = OxfordIIITPet(root='./dataset', split='test', target_types='binary-category', transform=transform, download=True)\n",
    "print(\"Dataset loaded. Number of training samples:\", len(train_dataset), \"Number of test samples:\", len(test_dataset))\n",
    "\n",
    "# Create DataLoader objects to efficiently load data in batches.\n",
    "# - train_loader: loads training data in batches of 32 and shuffles the data each epoch (improves generalization).\n",
    "# - test_loader: loads test data in batches of 32 without shuffling (for consistent evaluation).\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Load a ResNet18 model pre-trained on ImageNet\n",
    "model = resnet18(weights='IMAGENET1K_V1')\n",
    "print(\"ResNet18 model loaded.\")\n",
    "\n",
    "# Freeze all the parameters in the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer to output 2 classes (cat vs dog)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "# Move the model to the selected device (GPU if available, else CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.002) # TUNE\n",
    "\n",
    "# Training loop\n",
    "def train_model(num_epochs):\n",
    "    model.train()  # Set model to training mode (enables dropout, batchnorm updates)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0  # Accumulate loss for this epoch\n",
    "        for imgs, labels in train_loader:  # Loop over each batch in the training data\n",
    "            imgs, labels = imgs.to(device), labels.to(device)  # Move data to GPU or CPU\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(imgs)  # Forward pass: compute model predictions\n",
    "            loss = criterion(outputs, labels)  # Compute loss between predictions and true labels\n",
    "            loss.backward()  # Backward pass: compute gradients\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            running_loss += loss.item()  # Add batch loss to epoch total\n",
    "        # Print average loss for this epoch\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "def test_model():\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, uses running stats for batchnorm)\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency during evaluation\n",
    "        for imgs, labels in test_loader:  # Iterate over the test dataset in batches\n",
    "            imgs, labels = imgs.to(device), labels.to(device)  # Move data to the appropriate device (CPU or GPU)\n",
    "            outputs = model(imgs)  # Get model predictions (logits) for the batch. shape: (batch_size, 2)\n",
    "            _, preds = torch.max(outputs, 1)  # Get the predicted class (index of max logit) for each sample\n",
    "            correct += (preds == labels).sum().item()  # Count how many predictions are correct in this batch\n",
    "            total += labels.size(0)  # Update the total number of samples seen so far\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.4f}%\")\n",
    "\n",
    "\n",
    "# Run training and testing\n",
    "start_time = time.time() # <--- RECORD START TIME\n",
    "train_model(num_epochs=30) # TUNE\n",
    "end_time = time.time() # <--- RECORD END TIME\n",
    "duration = end_time - start_time\n",
    "print(f\"Training time: {duration/60:.2f} minutes\")\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e024d0f-8475-4d1e-bb33-05e8e3eab9e2",
   "metadata": {},
   "source": [
    "**Test Accuracy**: 99.0188%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da0b75-3b41-4e40-aeb3-3c6143cef2dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2efd7-587f-4149-9b57-8b4cfbe8c9fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transforms for multi-class\n",
    "train_transform_multi = transforms.Compose([\n",
    "    #transforms.Resize(224), # DEFAULT\n",
    "    #transforms.CenterCrop(224), # DEFAULT\n",
    "    transforms.RandomResizedCrop(224, scale=(0.75, 1.0)), # Randomly crop the image to 224x224 with a scale of 75% to 100%\n",
    "    transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally with 50% probability\n",
    "    transforms.RandomRotation(15), # Randomly rotate the image by up to +/- 15 degrees\n",
    "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05), # Augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform_multi = transforms.Compose([ # Minimal for test/val\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Custom Dataset wrapper to apply a specific transform\n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "def setup_dataloaders(root_dir='./dataset', val_fraction=0.2, batch_size=32, num_workers=2, pin_memory=True,\n",
    "                      train_transform=None, test_transform=None):\n",
    "    \"\"\"Loads data, splits, and creates DataLoaders.\"\"\"\n",
    "    # Load dataset for multi-class breed classification\n",
    "    base_train_val_dataset = OxfordIIITPet(root=root_dir, split='trainval', target_types='category', download=True)\n",
    "    test_dataset_multi_raw = OxfordIIITPet(root=root_dir, split='test', target_types='category', download=True)\n",
    "\n",
    "    # Split training data for validation\n",
    "    num_train_val_samples = len(base_train_val_dataset)\n",
    "    num_val_samples = int(val_fraction * num_train_val_samples)\n",
    "    num_train_samples_for_split = num_train_val_samples - num_val_samples\n",
    "\n",
    "    # These subsets will contain (PIL Image, label) tuples\n",
    "    train_subset_raw, val_subset_raw = random_split(base_train_val_dataset, [num_train_samples_for_split, num_val_samples])\n",
    "\n",
    "    # Now apply the correct transforms using the wrapper\n",
    "    train_subset_multi = TransformedDataset(train_subset_raw, transform=train_transform)\n",
    "    val_subset_multi = TransformedDataset(val_subset_raw, transform=test_transform)\n",
    "    test_dataset_multi = TransformedDataset(test_dataset_multi_raw, transform=test_transform)\n",
    "    \n",
    "    print(f\"Multi-class Dataset loaded. Training samples: {len(train_subset_multi)}, Validation samples: {len(val_subset_multi)}, Test samples: {len(test_dataset_multi)}\")\n",
    "\n",
    "    # Create DataLoader objects for the actual data subsets. shuffle=True shuffles the data each epoch\n",
    "    train_loader = DataLoader(train_subset_multi, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    val_loader = DataLoader(val_subset_multi, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_dataset_multi, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels_batch in train_loader:\n",
    "        imgs, labels_batch = imgs.to(device), labels_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_epoch_loss = running_loss / len(train_loader)\n",
    "    return avg_epoch_loss\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader_to_use, criterion, device):\n",
    "    \"\"\"Evaluates the model on a given loader.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels_batch in loader_to_use:\n",
    "            imgs, labels_batch = imgs.to(device), labels_batch.to(device)\n",
    "            outputs = model(imgs)\n",
    "            if criterion: # Calculate loss if criterion is provided\n",
    "                loss = criterion(outputs, labels_batch)\n",
    "                running_loss += loss.item()\n",
    "            # For multi-class, outputs.shape will be (batch_size, 37)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels_batch).sum().item()\n",
    "            total += labels_batch.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = running_loss / len(loader_to_use) if criterion and len(loader_to_use) > 0 else 0.0\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def run_fine_tuning_strategy_1(num_epochs, lr_fc, lr_backbone, device,\n",
    "                               train_loader, val_loader, test_loader,\n",
    "                               num_classes=37, model_save_prefix=\"strategy1_best_model\",\n",
    "                               factor=0.1, patience=2):\n",
    "    \"\"\"\n",
    "    Implements Strategy 1: Fine-tune l layers simultaneously with different LRs.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting Fine-Tuning Strategy 1...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    val_accuracies_per_l = {}\n",
    "    best_overall_val_accuracy = 0.0\n",
    "    best_l_config_for_strategy = None\n",
    "    \n",
    "    max_l = 4 # For ResNet18\n",
    "\n",
    "    for l_val in range(1, max_l + 1):\n",
    "        print(f\"\\n    STRATEGY 1: Training with FC + last {l_val} ResNet block(s) unfrozen\")\n",
    "\n",
    "        # Initialize model for current l_val\n",
    "        current_model = resnet18(weights='IMAGENET1K_V1')\n",
    "        # Freeze all parameters initially\n",
    "        for param in current_model.parameters():\n",
    "            param.requires_grad = False\n",
    "            # Replace the final fully connected layer (always trainable). model.fc.parameters() are requires_grad=True by default\n",
    "        current_model.fc = nn.Linear(current_model.fc.in_features, num_classes)\n",
    "        \n",
    "        # Unfreeze layers\n",
    "        current_backbone_params = []\n",
    "        if l_val >= 1: # Unfreeze layer4\n",
    "            print(\"    Unfreezing model.layer4\")\n",
    "            for param in current_model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "                current_backbone_params.append(param)\n",
    "        if l_val >= 2: # Unfreeze layer3\n",
    "            print(\"    Unfreezing model.layer3\")\n",
    "            for param in current_model.layer3.parameters():\n",
    "                param.requires_grad = True\n",
    "                current_backbone_params.append(param)\n",
    "        if l_val >= 3: # Unfreeze layer2\n",
    "            print(\"    Unfreezing model.layer2\")\n",
    "            for param in current_model.layer2.parameters():\n",
    "                param.requires_grad = True\n",
    "                current_backbone_params.append(param)\n",
    "        if l_val >= 4: # Unfreeze layer1\n",
    "            print(\"    Unfreezing model.layer1\")\n",
    "            for param in current_model.layer1.parameters():\n",
    "                param.requires_grad = True\n",
    "                current_backbone_params.append(param)\n",
    "        \n",
    "        current_model = current_model.to(device)\n",
    "        \n",
    "        # Optimizer and Criterion for current l_val\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        optimizer_grouped_parameters = [{'params': current_model.fc.parameters(), 'lr': lr_fc}]\n",
    "        if current_backbone_params:\n",
    "            optimizer_grouped_parameters.append({'params': current_backbone_params, 'lr': lr_backbone})\n",
    "        \n",
    "        current_optimizer = optim.Adam(optimizer_grouped_parameters)\n",
    "        # --- Initialize ReduceLROnPlateau Scheduler ---\n",
    "        # mode='max' for accuracy, 'min' for loss.\n",
    "        # factor: Factor by which the learning rate will be reduced. new_lr = lr * factor.\n",
    "        # patience: Number of epochs with no improvement after which learning rate will be reduced.\n",
    "        # verbose=True: Prints a message when the learning rate is reduced.\n",
    "        #scheduler = optim.lr_scheduler.ReduceLROnPlateau(current_optimizer, mode='max', factor=factor, patience=patience, verbose=True) # TUNE\n",
    "\n",
    "        total_trainable_params_in_current_model = 0\n",
    "        # Iterate over all parameters of the current_model being used for this l_val\n",
    "        for param in current_model.parameters():\n",
    "            if param.requires_grad:\n",
    "                total_trainable_params_in_current_model += param.numel()\n",
    "        print(f\"    Number of trainable parameters for l={l_val}: {total_trainable_params_in_current_model}\")\n",
    "\n",
    "        print(f\"    Starting training for l={l_val}, epochs={num_epochs}...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            avg_train_loss = train_one_epoch(current_model, train_loader, current_optimizer, criterion, device)\n",
    "            \n",
    "            # Perform validation within the epoch loop for ReduceLROnPlateau\n",
    "            epoch_val_accuracy, epoch_val_loss = evaluate_model(current_model, val_loader, criterion, device)\n",
    "            current_lrs = [group['lr'] for group in current_optimizer.param_groups]\n",
    "            print(f\"    l={l_val}, Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Acc: {epoch_val_accuracy:.2f}%, Val Loss: {epoch_val_loss:.4f}, LRs: {current_lrs}\")\n",
    "\n",
    "            # Step the ReduceLROnPlateau scheduler with the validation accuracy\n",
    "            #scheduler.step(epoch_val_accuracy) \n",
    "\n",
    "        # Perform validation for current l_val\n",
    "        print(f\"    Validating for l={l_val}...\")\n",
    "        current_l_val_accuracy, current_l_val_loss = evaluate_model(current_model, val_loader, criterion, device)\n",
    "        val_accuracies_per_l[l_val] = current_l_val_accuracy\n",
    "        print(f\"    Validation Accuracy for l={l_val}: {current_l_val_accuracy:.4f}%, Val Loss: {current_l_val_loss:.4f}\")\n",
    "\n",
    "        if current_l_val_accuracy > best_overall_val_accuracy:\n",
    "            best_overall_val_accuracy = current_l_val_accuracy\n",
    "            best_l_config_for_strategy = l_val\n",
    "            # Save the best model's state_dict\n",
    "            torch.save(current_model.state_dict(), f'{model_save_prefix}_l_{best_l_config_for_strategy}.pth')\n",
    "            print(f\"    Saved new best model (l={best_l_config_for_strategy})\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    strategy_duration_minutes = (end_time - start_time) / 60\n",
    "    \n",
    "    # After the loop, evaluate the best configuration on the test set\n",
    "    final_test_accuracy_for_strategy = 0.0\n",
    "    if best_l_config_for_strategy is not None:\n",
    "        print(f\"\\n--- Strategy 1 Evaluation ---\")\n",
    "        print(f\"Best l based on validation accuracy: {best_l_config_for_strategy} (Val Acc: {val_accuracies_per_l[best_l_config_for_strategy]:.4f}%)\")\n",
    "        print(f\"Loading and evaluating best model (l={best_l_config_for_strategy}) on the Test Set...\")\n",
    "        \n",
    "        # Re-setup the model architecture for the best_l_config\n",
    "        best_model_for_strategy = resnet18(weights=None) # Initialize without pre-trained weights if loading all\n",
    "        best_model_for_strategy.fc = nn.Linear(best_model_for_strategy.fc.in_features, num_classes) # Replace the final fully connected layer to match the saved model\n",
    "        best_model_for_strategy.load_state_dict(torch.load(f'{model_save_prefix}_l_{best_l_config_for_strategy}.pth', weights_only=True)) # Load the saved state dictionary for the best model\n",
    "        best_model_for_strategy = best_model_for_strategy.to(device)\n",
    "        \n",
    "        criterion_for_eval = nn.CrossEntropyLoss() # Re-init criterion for safety or pass it\n",
    "        final_test_accuracy_for_strategy, _ = evaluate_model(best_model_for_strategy, test_loader, criterion_for_eval, device)\n",
    "        print(f\"Final Test Accuracy (best l={best_l_config_for_strategy}): {final_test_accuracy_for_strategy:.4f}%\")\n",
    "    else:\n",
    "        print(\"No best configuration found for Strategy 1.\")\n",
    "\n",
    "    print(f\"Training time: {strategy_duration_minutes:.2f} minutes\")\n",
    "    \n",
    "    return {\n",
    "        \"best_l\": best_l_config_for_strategy,\n",
    "        \"best_val_acc\": best_overall_val_accuracy,\n",
    "        \"test_acc_of_best_l\": final_test_accuracy_for_strategy,\n",
    "        \"duration_minutes\": strategy_duration_minutes,\n",
    "        \"val_accuracies_per_l\": val_accuracies_per_l\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# --- Run Strategy 1 ---\n",
    "\n",
    "# These transforms are defined globally above\n",
    "actual_train_loader, actual_val_loader, actual_test_loader = setup_dataloaders(\n",
    "    train_transform=train_transform_multi,\n",
    "    test_transform=test_transform_multi\n",
    "    # val_fraction=0.2, batch_size=32, num_workers=2, pin_memory=True # DEFAULT VALUES\n",
    ")\n",
    "\n",
    "num_epochs_s1 = 15  # TUNE\n",
    "# Learning rates for FC and backbone\n",
    "lr_fc_s1 = 1e-4       # TUNE\n",
    "lr_backbone_s1 = 1e-4 # TUNE\n",
    "# Learning rate decay factor and patience for ReduceLROnPlateau\n",
    "factor = 0.1 # TUNE\n",
    "patience = 2 # TUNE\n",
    "\n",
    "_ = run_fine_tuning_strategy_1(\n",
    "    num_epochs=num_epochs_s1,\n",
    "    lr_fc=lr_fc_s1,\n",
    "    lr_backbone=lr_backbone_s1,\n",
    "    device=device,\n",
    "    train_loader=actual_train_loader,\n",
    "    val_loader=actual_val_loader,\n",
    "    test_loader=actual_test_loader,\n",
    "    num_classes=37,\n",
    "    model_save_prefix=\"strategy1_best_model\",\n",
    "    factor=factor, patience=patience\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19308a-15bb-4d9a-9470-c6add17ce60b",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9af57-7f7a-4359-82ec-e9d0298a4e79",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Strategy 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e837740-2cb8-4c60-836c-c1e2da6a8770",
   "metadata": {},
   "source": [
    "*Data augmentation:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cd81b-0840-45d8-84c3-1c2f0b71056d",
   "metadata": {},
   "source": [
    "BASELINE (num_epochs_strat1 = 20, lr_strat1 = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c37c00-4941-48b3-a980-8f82c975c92b",
   "metadata": {},
   "source": [
    "--- Strategy 1 Finished ---\n",
    "Best l based on validation accuracy: 3 (Accuracy: 90.7609%)\n",
    "Loading and evaluating best model (l=3) on the Test Set...\n",
    "Final Test Accuracy (with best l=3 config): 88.6618%\n",
    "Strategy 1 training time: 12.88 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004dbf6-4ad6-4296-81eb-72027c691774",
   "metadata": {},
   "source": [
    "BASELINE (num_epochs_strat1 = 20, lr_strat1 = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f645964-bdd5-4109-8c20-b574946a6a1c",
   "metadata": {},
   "source": [
    "--- Strategy 1 Finished ---\n",
    "Best l based on validation accuracy: 2 (Accuracy: 89.5380%)\n",
    "Loading and evaluating best model (l=2) on the Test Set...\n",
    "Final Test Accuracy (with best l=2 config): 88.2529%\n",
    "Strategy 1 training time: 17.58 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48077064-0667-4db9-afd4-1f154f04c0ff",
   "metadata": {},
   "source": [
    "BASELINE (num_epochs_strat1 = 15, lr_strat1 = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260e550-7c14-43e3-b9f5-3993362a8e62",
   "metadata": {},
   "source": [
    "--- Strategy 1 Finished ---\n",
    "Best l based on validation accuracy: 3 (Accuracy: 91.8478%)\n",
    "Loading and evaluating best model (l=3) on the Test Set...\n",
    "Final Test Accuracy (with best l=3 config): 88.0076%\n",
    "Strategy 1 training time: 12.47 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a99139-d1ef-4470-8a2f-220fcc2ccb5f",
   "metadata": {},
   "source": [
    "----> BASELINE (num_epochs_strat1 = 15, lr_strat1 = 1e-4) <---- BEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbafe3-0d57-4781-a754-105690dad6f2",
   "metadata": {},
   "source": [
    "--- Strategy 1 Finished ---\n",
    "Best l based on validation accuracy: 3 (Accuracy: 91.0326%)\n",
    "Loading and evaluating best model (l=3) on the Test Set...\n",
    "Final Test Accuracy (with best l=3 config): 89.0161%\n",
    "Strategy 1 training time: 16.78 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092686b7-d282-4794-a454-38f881b1337b",
   "metadata": {},
   "source": [
    "Adding RandomResizedCrop (basically the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d595e-2d03-4aeb-8818-c26233737c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "--- Strategy 1 Finished ---\n",
    "Best l based on validation accuracy: 1 (Accuracy: 92.5272%)\n",
    "Loading and evaluating best model (l=1) on the Test Set...\n",
    "Final Test Accuracy (with best l=1 config): 89.1251%\n",
    "Strategy 1 training time: 10.66 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ad361-6a14-46ba-ba0b-46b5b6d4821d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Adding RandomHorizontalFlip (almost the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073709aa-4a64-45db-8ea9-a84bd85119ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "--- Strategy 1 Finished ---\n",
    "Best l based on validation accuracy: 3 (Accuracy: 92.6630%)\n",
    "Loading and evaluating best model (l=3) on the Test Set...\n",
    "Final Test Accuracy (with best l=3 config): 89.8337%\n",
    "Strategy 1 training time: 10.72 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c28a130-dcb3-467d-95c6-ac8a48a74450",
   "metadata": {},
   "source": [
    "Adding RandomRotation (irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7170e4-154e-4552-87d2-cfb9c0bbdbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "--- Strategy 1 Evaluation ---\n",
    "Best l based on validation accuracy: 2 (Val Acc: 92.5272%)\n",
    "Loading and evaluating best model (l=2) on the Test Set...\n",
    "Final Test Accuracy (best l=2): 87.7351%\n",
    "Training time: 11.07 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997638b-494f-42b8-a7ab-2cebb49202cd",
   "metadata": {},
   "source": [
    "**Key takeaway**: Data augmentation didn't seem to improve accuracy. Kept tho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43476300-6e12-4d32-8a7e-a06970b140a6",
   "metadata": {},
   "source": [
    "**TO DO**: Copy new version of the code from vscode and test the other improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e7046-a5fd-456b-8271-186524a68ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342c41e-e897-4954-9213-6dc814d3a2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
